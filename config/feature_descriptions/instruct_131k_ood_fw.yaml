target_model_path: meta-llama/Llama-3.1-8B
model_path: meta-llama/Llama-3.1-8B-Instruct
continuous_tokens:
  "begin_continuous": "<|reserved_special_token_10|>"
  "end_continuous": "<|reserved_special_token_11|>"
  "continuous_rep": "<|reserved_special_token_12|>"
output_dir: /data/artifacts/bzl/autointerp/checkpoints/SAE_feature_explainer_basellama_basellama_131k_dec_lora
cache_dir: /data/artifacts/bzl/autointerp/checkpoints/
train:
  num_samples: 100000000
  batch_size: 64
  save_strategy: steps
  save_total_limit: 10
  save_steps: 8000
  learning_rate: !!float 5e-5
  num_epochs: 10
  eval_strategy: steps
  eval_steps: 8000
  peft_lora: true
  lora_r: 128
  dataset: ["sae_explanations"]
  evaluation_type: mixed
  explanation_dir: /data/artifacts/bzl/autointerp/datasets/SAE_feature_explanations_llama3.1_8b/
  split_keys: explanations/{split}_layer_feature_idxs.pkl
  split_explanations_data: explanations/{split}_explanations.pkl
  sae_save_path: features
  layers: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]
  bf16: true
  tasks:
    features_explain:
      question_types:
        generative_explanation:
          evaluation_type: semantic_similarity
          weight: 1.0
          prompts:
            - messages:
                - role: "user"
                  content: "Generate a description of this feature at layer {layer}: {begin_continuous}{feature}{end_continuous}"
                - role: "assistant"
                  content: ""
            - messages:
                - role: "user"
                  content: "What does {begin_continuous}{feature}{end_continuous} encode at layer {layer}?"
                - role: "assistant"
                  content: ""
            - messages:
                - role: "user"
                  content: "{begin_continuous}{feature}{end_continuous} activates at layer {layer} for inputs with the following features:"
                - role: "assistant"

test:
  batch_size: 64
  tasks:
    features_explain:
      num_samples: 1600
      dataset: ["custom_explanations"]
      simulator_path: Transluce/features_explain_llama3.1_8b_simulator
      evaluation_type: simulator_correlation
      explanation_dir: /data/artifacts/bzl/autointerp/datasets/fineweb_llama_3.1_8b_95seqlen_fineweb_acts_grads_-1.0/
      split_keys: "{split}_indices.json"
      split_explanations_data: "{split}_indices.json"
      exemplar_config_path: exemplar_config.json
      vectors_save_path: "{split}_vectors.pt"
